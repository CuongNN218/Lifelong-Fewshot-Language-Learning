{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import datasets\n",
    "import random\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_to_keys = {\n",
    "            \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "            \"qqp\": (\"question1\", \"question2\"),\n",
    "            \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "            \"sst2\": (\"sentence\", None),\n",
    "            \"boolq\": (\"passage\", \"question\"),\n",
    "            \"copa\": ('choice1', 'choice2', 'premise', 'question'),\n",
    "            \"wic\": (\"start1\", \"end1\", \"sentence1\", \"start2\", \"end2\", \"sentence2\", \"word\"),\n",
    "            \"wsc\": (\"span1_text\", \"span1_index\", \"span2_text\", \"span2_index\", \"text\"),\n",
    "            \"wsc_bool\": (\"span1_text\", \"span1_index\", \"span2_text\", \"span2_index\", \"text\"),\n",
    "            \"cb\": (\"premise\", \"hypothesis\"),\n",
    "            \"record\": (\"passage\", \"query\", \"entities\"),\n",
    "            \"multirc\": (\"question\", \"answer\", \"paragraph\"),\n",
    "            \"rte_superglue\": (\"premise\", \"hypothesis\"),\n",
    "            \"imdb\": (\"text\", None),\n",
    "            \"ag_news\": (\"text\", None),\n",
    "            \"yelp_review_full\": (\"text\", None),\n",
    "            \"yahoo_answers_topics\": (\"question_content\", \"best_answer\"),\n",
    "            \"dbpedia_14\": (\"title\", \"content\"),\n",
    "            \"amazon\": (\"content\", None)}\n",
    "\n",
    "task_to_labels = {\n",
    "            \"mnli\": {\"label\": (\"entailment\", \"neutral\", \"contradiction\"), \"fold\": \"mnli_csv\"},\n",
    "            \"qqp\": {\"label\": (\"not_duplicate\", \"duplicate\"), \"fold\": \"qqp_csv\"},\n",
    "            \"rte\": {\"label\": (\"entailment\", \"not_entailment\"), \"fold\": \"rte_csv\"},\n",
    "            \"sst2\": { \"label\": (\"negative\", \"positive\"), \"fold\": \"sst2_csv\"},\n",
    "            \"boolq\": {\"label\": (\"false\", \"true\"), \"fold\": \"boolq_csv\"},\n",
    "            \"copa\": {\"label\": (\"false\", \"true\"), \"fold\": \"copa_csv\"},\n",
    "            \"wic\": {\"label\": (\"false\", \"true\"), \"fold\": \"wic_csv\"},\n",
    "            \"cb\": {\"label\": (\"entailment\", \"contradiction\", \"neutral\"), \"fold\": \"cb_csv\"},\n",
    "            \"multirc\": {\"label\": (\"false\", \"true\"), \"fold\": \"multirc_csv\"},\n",
    "            \"imdb\": {\"label\": (\"negative\", \"positive\"), \"fold\": \"imdb_csv\"},\n",
    "            \"ag_news\": {\"label\": (\"world\", \"sports\", \"business\", \"science\"), \"fold\": \"ag_news_csv\"},\n",
    "            \"yelp_review_full\": {\"label\":(\"terrible\", \"bad\", \"middle\", \"good\", \"wonderful\"), \"fold\": \"yelp_review_full_csv\"},\n",
    "            \"yahoo_answers_topics\":{\"label\" : (\"society and culture\", \"science\", \"health\", \"education and reference\",\n",
    "                                     \"computers and internet\", \"sports\", \"business\", \"entertainment and music\",\n",
    "                                     \"family and relationships\", \"politics and government\"), \"fold\" : \"yahoo_answers_csv\"},\n",
    "            \"dbpedia_14\": {\"label\": (\"company\", \"educationalinstitution\", \"artist\", \"athlete\", \"officeholder\",\n",
    "                           \"meanoftransportation\", \"building\", \"naturalplace\", \"village\", \"animal\",\n",
    "                           \"plant\", \"album\", \"film\", \"writtenwork\"), \"fold\" : \"dbpedia_csv\"},\n",
    "            \"amazon\": {\"label\": (\"terrible\", \"bad\", \"middle\", \"good\", \"wonderful\"), \"fold\": \"amazon_csv\"}\n",
    "        }\n",
    "glue_datasets = ['cola', 'sst2', 'mrpc', 'qqp', 'stsb', 'mnli', 'mnli_mismatched', 'mnli_matched', 'qnli', 'rte', 'wnli', 'ax']\n",
    "superglue_datasets = ['copa', 'boolq', 'wic', 'wsc', 'cb', 'record', 'multirc', 'rte_superglue', 'wsc_bool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chia vao cac folder theo format run_seed/train(test/valid).txt\n",
    "runs = [0, 1, 2]\n",
    "seed = 0\n",
    "fewshotnum = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples, task, label_key):\n",
    "    keys = task_to_keys[task]\n",
    "    if keys[1]!=None:\n",
    "        text = ''\n",
    "        for key in keys:\n",
    "            text += key + ': ' + str(examples[key]) + ' '\n",
    "    else:\n",
    "        text = examples[keys[0]]\n",
    "\n",
    "    target = task_to_labels[task]['label'][examples[label_key]]\n",
    "    return {\"text\": text, \"target\": target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out path:  longseqtextclsdata/amazon_csv/0_0\n",
      "Task label key:  label\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a145f3c7209446280f9cbac7c6ab658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/115000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046fc5d083504d6a948ca6d892d3c48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out path:  longseqtextclsdata/amazon_csv/1_100\n",
      "Task label key:  label\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4360eb4e985345feb7b8290a68f0e4a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/115000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd917b611a242d49c0fed0c77746ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out path:  longseqtextclsdata/amazon_csv/2_200\n",
      "Task label key:  label\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8c9ea0706e41a6ba6d7832a7414d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/115000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1941a0eae9304447bbd3090cc98b833d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load all datasets \n",
    "# for faster create datasets, change datasets outside the loop: \n",
    "dataset_names = [key for key in task_to_labels.keys()]\n",
    "for run in runs:\n",
    "    curr_seed = seed + run * 100\n",
    "    for name in dataset_names:\n",
    "        # if name != 'amazon':\n",
    "        #     continue\n",
    "        outpath = \"longseqtextclsdata/\" + task_to_labels[name][\"fold\"] + '/' + str(run) + '_' + str(curr_seed)\n",
    "        print(\"out path: \", outpath)\n",
    "        if not os.path.exists(outpath):\n",
    "            os.makedirs(outpath)\n",
    "\n",
    "        label_key = 'label' if 'yahoo_' not in name else 'topic'\n",
    "        print(\"Task label key: \", label_key)\n",
    "        \n",
    "        if name == 'mnli':\n",
    "            dataset_train = load_dataset(\"LysandreJik/glue-mnli-train\", split='train')\n",
    "            dataset_test = load_dataset(\"LysandreJik/glue-mnli-train\", split='validation')\n",
    "        elif name == 'amazon':\n",
    "            # load train\n",
    "            prefix_path = '/home/nguyen/projects/prompt_cl/datasets/src/data/amazon'\n",
    "            df = pd.read_csv(os.path.join(prefix_path,\"train.csv\"), header=None)\n",
    "            df = df.rename(columns={0: \"label\", 1: \"title\", 2: \"content\"})\n",
    "            df['label'] = df['label'] - 1\n",
    "            dataset_train = datasets.Dataset.from_pandas(df)\n",
    "            \n",
    "            # load test\n",
    "            df = pd.read_csv(os.path.join(prefix_path,'test.csv'), header=None)\n",
    "            df = df.rename(columns={0: \"label\", 1: \"title\", 2: \"content\"})\n",
    "            df['label'] = df['label'] - 1\n",
    "            dataset_test = datasets.Dataset.from_pandas(df)\n",
    "        else:\n",
    "            if name not in glue_datasets and name not in superglue_datasets:\n",
    "                print(\"Task not glue\", name)\n",
    "                dataset_train = load_dataset(name, split='train')\n",
    "                dataset_test = load_dataset(name, split='test')\n",
    "            else:\n",
    "                benchmark = 'glue' if name in glue_datasets else 'super_glue'\n",
    "                dataset_train = load_dataset(benchmark,\n",
    "                                             name.replace('_superglue', '').replace('_bool', ''),\n",
    "                                             split=\"train\")\n",
    "                dataset_test = load_dataset(benchmark,\n",
    "                                             name.replace('_superglue', '').replace('_bool', ''),\n",
    "                                             split=\"validation\")\n",
    "\n",
    "        # processed datasets:\n",
    "        dataset_train = dataset_train.map(lambda x: preprocess_function(x, name, label_key))\n",
    "        dataset_test = dataset_test.map(lambda x: preprocess_function(x, name, label_key))\n",
    "\n",
    "        all_label = []\n",
    "        trainresult = {}\n",
    "        for item in dataset_train:\n",
    "            if item[\"target\"] not in all_label:\n",
    "                all_label.append(item[\"target\"])\n",
    "            # replace all \\t by space\n",
    "            text = item['text'].replace(\"\\t\", \" \")\n",
    "            if item[\"target\"] not in trainresult.keys():\n",
    "                trainresult[item[\"target\"]] = [text]\n",
    "            else:\n",
    "                trainresult[item[\"target\"]].append(text)\n",
    "        \n",
    "        testresult = {}\n",
    "        for item in dataset_test:\n",
    "            # replace all \\t by space\n",
    "            text = item['text'].replace(\"\\t\", \" \")\n",
    "            if item[\"target\"] not in testresult.keys():\n",
    "                testresult[item[\"target\"]] = [text]\n",
    "            else:\n",
    "                testresult[item[\"target\"]].append(text)\n",
    "        \n",
    "        fewtrainname = os.path.join(outpath, \"train.txt\")\n",
    "        fewvalidname = os.path.join(outpath, \"valid.txt\")\n",
    "        fewtestname = os.path.join(outpath, \"test.txt\")\n",
    "        tousetres = {}\n",
    "        for key in trainresult.keys():\n",
    "            if 2 * fewshotnum < len(trainresult[key]):\n",
    "                thisres = random.sample(trainresult[key], 2 * fewshotnum)\n",
    "            else:\n",
    "                thisres = trainresult[key]\n",
    "            tousetres[key] = thisres\n",
    "\n",
    "        sampletestres = {}\n",
    "        for key in testresult.keys():\n",
    "            sampletestnum = 500\n",
    "            if sampletestnum < len(testresult[key]):\n",
    "                thisres = random.sample(testresult[key], sampletestnum)\n",
    "            else:\n",
    "                thisres = testresult[key]\n",
    "            sampletestres[key] = thisres\n",
    "\n",
    "        tousetrainres = {}\n",
    "        tousevalidres = {}\n",
    "        for key in tousetres.keys():\n",
    "            allres = tousetres[key]\n",
    "            fortrain = allres[0:fewshotnum]\n",
    "            forvalid = allres[fewshotnum:2 * fewshotnum]\n",
    "            tousetrainres[key] = fortrain\n",
    "            tousevalidres[key] = forvalid\n",
    "        f = open(fewtrainname,'w')\n",
    "        for key in tousetrainres.keys():\n",
    "            for one in tousetrainres[key]:\n",
    "                f.write(one+\"\\t\"+key + \"\\n\")\n",
    "        f.close()\n",
    "\n",
    "        f = open(fewvalidname, 'w')\n",
    "        for key in tousevalidres.keys():\n",
    "            for one in tousevalidres[key]:\n",
    "                f.write(one + \"\\t\" + key + \"\\n\")\n",
    "        f.close()\n",
    "        ####test\n",
    "        f = open(fewtestname, 'w')\n",
    "        for key in sampletestres.keys():\n",
    "            for one in sampletestres[key]:\n",
    "                f.write(one + \"\\t\" + key + \"\\n\")\n",
    "        f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
